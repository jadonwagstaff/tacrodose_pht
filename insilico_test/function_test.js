// Run with Node.js
// Install fs and csvsync first with
// npm install fs --save
// npm install csvsync --save
console.log("Functionality Test");
console.log("Tests functionality of decision support tool by comparing the tool's calculations to calculations generated by NONMEM.");
console.log("");

// Load packages
var fs = require('fs');
var csvsync = require('csvsync');

// Load functions to test
eval(fs.readFileSync('../public/js/bayesian_update.js')+'');
eval(fs.readFileSync('../public/js/estimate_dose.js')+'');
eval(fs.readFileSync('../public/js/manage_events.js')+'');
eval(fs.readFileSync('../public/js/manage_timeline.js')+'');
eval(fs.readFileSync('../public/js/predict_conc.js')+'');

// initialize variables
var model = {
	tvk: 0.0408,			// typical value for elimination rate
	tvkf: 0.0268,			// typical value for elimination rate with concomitant fluconazole
	tvv: 233,				// typical value for volume
	ka: 3.43,				// absorption rate
	eagey: 0.775,			// exponent for age
	egfr: 0.851,			// exponent for creatinine
	dfluc: 0.657,			// exponent for fluconazole
	frac: 1,				// fraction absorbed
	invomgk: 3.817,			// inverse omega value corresponding to k
	invomgv: 3.040,			// inverse omega value corresponding to v
	sigma: 13.6,		 	// sigma value
	age: 0,					// patient age
	route: "oral"			// route of administration
};
var eta = {
	k: 0,					// eta value for k
	v: 0					// eta value for v
};
var target = 12;
var route = "oral";
var freq = 12;
var fluc = NaN;
var creat = [{
	dt: NaN,
	value: NaN
}];
var errors = {
	k_max: 0,				// maximum error for calculation of k
	k_mean: 0,				// mean error for calculation of k
	v_max: 0,				// maximum error for calculation of v
	v_mean: 0,				// mean error for calculation of v
	conc_max: 0,			// maximum error for calculation of cencentration
	conc_mean: 0,			// mean error for calculation of cencentration
	dose_max: 0,			// maximum error for calculation of steady state concentration
	dose_mean: 0,			// mean error for calculation of steady state concentration
	etak_max: 0,			// maximum error for calculation of eta value for k
	etak_mean: 0,			// mean error for calculation of eta value for k
	etav_max: 0,			// maximum error for calculation of eta value for v
	etav_mean: 0			// mean error for calculation of eta value for v
};



////////////////////////////////////////////////////////////////////////////////
// TEST FUNCTIONS
////////////////////////////////////////////////////////////////////////////////

// check_k_v
//
// Checks the accuracy of calculation of the elimination constant (k) and volume
// of distribution (v) based on eta values and covariates.
//
// Parameters:
//	 de: de obtained from an outside source whith correct k and v
//   timeline: used to get de with k and v predicted by the app
//   model: Pharmacokinetic model parameters for use in get_de()
// 	 eta: Eta values used in get_de()
//
// Returns: 
//   Errors between k and v values in de and values calculated by get_de() as a 
//   proportion of values in de.
//
function check_k_v(de, timeline, model, eta) {
	let errors = [];
	let de_pred = get_de(timeline, model, eta); // manage_events.js
	let t = false;
	
	// first values for k and v
	let val_k = de[0].k + "";
	val_k = Math.abs(val_k.replace(".", "")) + "";
	let val_v = de[0].v + "";
	val_v = Math.abs(val_v.replace(".", "")) + "";
	errors.push({k: parseFloat((de[0].k - de_pred[0].k.toPrecision(val_k.length)).toPrecision(val_k.length)) / de[0].k,
				 v: parseFloat((de[0].v - de_pred[0].v.toPrecision(val_v.length)).toPrecision(val_v.length)) / de[0].v});
	// subsequent values for k and v
	for (let i = 1; i < de_pred.length; i++) {
		val_k = de[i-1].k + "";
		val_k = Math.abs(val_k.replace(".", "")) + "";
		val_v = de[i].v + "";
		val_v = Math.abs(val_v.replace(".", "")) + "";
		errors.push({k: parseFloat((de[i-1].k - de_pred[i].k.toPrecision(val_k.length)).toPrecision(val_k.length)) / de[i-1].k,
					 v: parseFloat((de[i-1].v - de_pred[i].v.toPrecision(val_v.length)).toPrecision(val_v.length)) / de[i-1].v});
	}
	
	return(errors);
}


// check_conc_prediction
//
// Checks the accuracy of concentration calculations based on given k, v, and 
// eta values.
//
// Parameters:
//	 de: de obtained from an outside source whith correct k and v
//   ce: ce with correct predicted concentration values
//   model: Pharmacokinetic model parameters for use in predict_conc()
//
// Returns: 
//   Errors between correct concentration values in ce and concentrations 
//   calculated by predict_conc() as a proportion of values in ce.
//
function check_conc_prediction(de, ce, model) {
	let errors = [];
	let pred = predict_conc(ce, de, model); // predict_conc.js
	
	for (let i = 0; i < pred.length; i++) {
		let val = ce[i].conc + "";
		val = Math.abs(val.replace(".", "")) + "";
		errors.push(parseFloat((ce[i].conc - pred[i].toPrecision(val.length)).toPrecision(val.length)) / ce[i].conc);
	}
	
	return(errors);
}


// check_dose_prediction
//
// Checks the dose prediction ability by comparing target trough concentrations 
// to trough concentrations at steady state (200 doses).
//
// Parameters:
//	 de: de obtained from an outside source whith correct k and v
//   ce: ce with correct predicted concentration values
//   model: Pharmacokinetic model parameters for use in predict_conc()
//
// Returns: 
//   Error between target trough concentration values and steady state 
//   concentration as a proportion of the target concentration.
//
function check_dose_prediction(target, route, freq, creat, fluc, model, eta) {
	let dose = estimate_dose(target, freq, creat, fluc, model, eta); // estimate_dose.js
	let timeline = [];
	let ce = [];
	let de = [];
	let predicted = NaN;
	
	// create timeline and de
	insert_timeline_item(timeline, 0, "fluc", fluc); // manage_timeline.js
	insert_timeline_item(timeline, 0, "creat", creat[0].value);
	insert_timeline_item(timeline, freq * 200 - 0.001, "conc", target);
	ce = get_ce(timeline);
	extend_timeline(timeline, dose, freq * 200, freq, route);
	de = get_de(timeline, model, eta);
	
	// predict the concentration just before the last dose
	predicted = predict_conc(ce, de, model)[0];
	
	return((predicted - target) / target);
}



////////////////////////////////////////////////////////////////////////////////
// COMPARE VALUES TO VALUES FROM NONMEM
////////////////////////////////////////////////////////////////////////////////
console.time("Run time");

// Concentration Simulations (330 patients based on 33 dosing regimens)
var file = fs.readFileSync("nonmem_simulation.csv");
var simu = csvsync.parse(file, {returnObject: true});

var id_count = 0;
var index = 0;

// process each patient
while (index < simu.length) {
	let timeline = [];
	let de = [];
	let ce = [];
	id_count++;
	
	// load patient-constant values
	let id = simu[index].ID;
	model.age = parseFloat(simu[index].AGEY);
	eta.v = parseFloat(simu[index].ETA2);
	eta.k = parseFloat(simu[index].ETA1);
	
	// process each patient-dose/concentration
	while (index < simu.length && simu[index].ID == id) {
		timeline.push({
			time: parseFloat(simu[index].TIME), 
			dose: parseFloat(simu[index].AMT), 
			route: "oral", 
			conc: parseFloat(simu[index].SIM_CONC), 
			fluc: parseFloat(simu[index].FLUC), 
			creat: parseFloat(simu[index].MSGFR)
		});
		// NONMEM applies the previous parameters to the next
		// time period, so the first dose/conentration is treated
		// differently
		if (index == simu.length - 1 || id != simu[index + 1].ID) {
			de.push({
				time: parseFloat(simu[index].TIME), 
				dose: parseFloat(simu[index].AMT), 
				route: "oral", 
				fluc: parseFloat(simu[index].FLUC), 
				creat: parseFloat(simu[index].MSGFR),
				k: parseFloat(simu[index].K),
				v: parseFloat(simu[index].V)
			});
		} else {
			de.push({
				time: parseFloat(simu[index].TIME), 
				dose: parseFloat(simu[index].AMT), 
				route: "oral", 
				fluc: parseFloat(simu[index].FLUC), 
				creat: parseFloat(simu[index].MSGFR),
				k: parseFloat(simu[index + 1].K),
				v: parseFloat(simu[index].V)
			});
		}
		ce.push({
			time: parseFloat(simu[index].TIME), 
			conc: parseFloat(simu[index].SIM_CONC)
		});
		index = index + 1;
	}
	
	// dose prediction test
	fluc = de[de.length - 1].fluc;
	creat[0].value = de[de.length - 1].creat;
	let dose_error = check_dose_prediction(target, route, freq, creat, fluc, model, eta);
	if (Math.abs(dose_error) > errors.dose_max) errors.dose_max = Math.abs(dose_error);
	errors.dose_mean += Math.abs(dose_error);

	// concentration prediction test
	let k_v_errors = check_k_v(de, timeline, model, eta);
	let conc_errors = check_conc_prediction(de, ce, model);
	for (var i = 0; i < k_v_errors.length; i++) {
		if(Math.abs(k_v_errors[i].k) > errors.k_max) errors.k_max = Math.abs(k_v_errors[i].k);
		errors.k_mean += Math.abs(k_v_errors[i].k);
		if(Math.abs(k_v_errors[i].v) > errors.v_max) errors.v_max = Math.abs(k_v_errors[i].v);
		errors.v_mean += Math.abs(k_v_errors[i].v);
		if(Math.abs(conc_errors[i]) > errors.conc_max) errors.conc_max = Math.abs(conc_errors[i]);
		errors.conc_mean += Math.abs(conc_errors[i]);
	}
}
// calculate means and change to percentage
errors.dose_max *= 100;
errors.dose_mean = 100 * errors.dose_mean / id_count;
errors.k_max *= 100;
errors.k_mean = 100 * errors.k_mean / index;
errors.v_max *= 100;
errors.v_mean = 100 * errors.v_mean / index;
errors.conc_max *= 100;
errors.conc_mean = 100 * errors.k_mean / index;



// Bayesian Predictions (33 patients with bayesian predicted etas)
file = fs.readFileSync("nonmem_bayesian_input.csv");
var bayes_in = csvsync.parse(file, {returnObject: true});
file = fs.readFileSync("nonmem_bayesian_output.csv");
var bayes_out = csvsync.parse(file, {returnObject: true});

index = 0;
id_count = 0;
while (index < bayes_in.length) {
	let timeline = [];
	let de = [];
	let ce = [];
	id_count++;
	
	// load patient-constant values
	id = bayes_in[index].ID;
	model.age = parseFloat(bayes_in[index].AGEY);
	eta = {k: 0, v: 0};
	nonmem_eta = {k: bayes_out[index].ETA1, v: bayes_out[index].ETA2};
	
	// process each patient-dose/concentration
	while (index < bayes_in.length && bayes_in[index].ID == id) {
		// NONMEM applies the previous parameters to the next
		// time period, so the first dose/conentration is treated
		// differently
		if (index == bayes_in.length - 1 || id != bayes_in[index + 1].ID) {
			if (bayes_in[index].AMT != ".") {
				timeline.push({
					time: parseFloat(bayes_in[index].TIME), 
					dose: parseFloat(bayes_in[index].AMT), 
					route: "oral", 
					conc: NaN, 
					fluc: parseFloat(bayes_in[index].FLUC), 
					creat: parseFloat(bayes_in[index].MSGFR)
				});
			}
			else if (bayes_in[index].DV != ".") {
				timeline.push({
					time: parseFloat(bayes_in[index].TIME), 
					dose: NaN, 
					route: NaN, 
					conc: parseFloat(bayes_in[index].DV), 
					fluc: parseFloat(bayes_in[index].FLUC), 
					creat: parseFloat(bayes_in[index].MSGFR)
				});
			}
		} else {
			if (bayes_in[index].AMT != ".") {
				timeline.push({
					time: parseFloat(bayes_in[index].TIME), 
					dose: parseFloat(bayes_in[index].AMT), 
					route: "oral", 
					conc: NaN, 
					fluc: parseFloat(bayes_in[index + 1].FLUC), 
					creat: parseFloat(bayes_in[index + 1].MSGFR)
				});
			}
			else if (bayes_in[index].DV != ".") {
				timeline.push({
					time: parseFloat(bayes_in[index].TIME), 
					dose: NaN, 
					route: NaN, 
					conc: parseFloat(bayes_in[index].DV), 
					fluc: parseFloat(bayes_in[index + 1].FLUC), 
					creat: parseFloat(bayes_in[index + 1].MSGFR)
				});
			}
		}
		index = index + 1;
	}
	
	// bayesian prediction test
	de = get_de(timeline, model, eta); // manage_events.js
	ce = get_ce(timeline); // manage_events.js
	eta = bayesian_update(de, ce, model, eta, .1, 10); // bayesian_update.js
	console.log(eta.k, nonmem_eta.k, (Math.abs(eta.k - nonmem_eta.k) / nonmem_eta.k), eta.v, nonmem_eta.v, (Math.abs(eta.v - nonmem_eta.v) / nonmem_eta.v))
	let eta_error = {k: (Math.abs(eta.k - nonmem_eta.k) / nonmem_eta.k), v: (Math.abs(eta.v - nonmem_eta.v) / nonmem_eta.v)};
	if(eta_error.k > errors.etak_max) errors.etak_max = eta_error.k;
	errors.etak_mean += eta_error.k;
	if(eta_error.v > errors.etav_max) errors.etav_max = eta_error.v;
	errors.etav_mean += eta_error.v;
}
// calculate means and change to percentage
errors.etak_max *= 100;
errors.etak_mean = 100 * errors.etak_mean / id_count;
errors.etav_max *= 100;
errors.etav_mean = 100 * errors.etav_mean / id_count;




////////////////////////////////////////////////////////////////////////////////
// OUTPUT RESULTS
////////////////////////////////////////////////////////////////////////////////
let message = "Differences in calculated values are reported as maximum and mean error as a percentage of values generated by NONMEM.";
message += " NONMEM was used to generate predicted concentrations based on 330 simulated patients with 33 different dosing regimens.";
message += " NONMEM was also used to estimate eta values based on 33 patient dosing and concentration values using MAP Bayes method.";
message += " Exponentiated eta values were compared since between subject variability for the elimination rate and volume of distribution were modeled as exponential.";
console.log(message);
console.log("");

message = "The elimination rate constant (k) and volume of distribution (v) is calculated from given eta values and patient covariates.";
message += " Concentrations (conc) are predicted based on a pharmacokinetic model, patient covariates, and eta values.";
message += " Assuming concentration predictions are accurate, the dose prediction (dose) values are evaluated by comparing trough concentrations after 200 doses to target trough concentrations.";
message += " The MAP Bayesian functionality of the tool estimates eta values (etak and etav) based on patient covariate, dosing, and concentration values.";
console.log(message);
console.log("");

console.timeEnd("Run time");
console.log("Percent errors:");
console.log(errors);























